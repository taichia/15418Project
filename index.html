<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>15418 Final Project by taichia</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>15418 Final Project</h1>
        <p></p>

        <p class="view"><a href="https://github.com/taichia/15418Project">View the Project on GitHub <small>taichia/15418Project</small></a></p>


        <ul>
          <li><a href="https://github.com/taichia/15418Project/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/taichia/15418Project/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/taichia/15418Project">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h3>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome to our 15418 Final Project.</h3>

<p>For our project, we are designing a Deep Boltzman Machine with parallel tampering on a GPU. </p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background Information</h3>

<p><a href="http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf">Deep Boltzmann Machines</a> are powerful generative models which are capable of doing unsupervised learning on large datasets. However, due to their expressivity, the training process is very much compute-bound. Our goal is to implement a Deep Boltzmann Machine training and inference program using modern-day GPUs. Boltzmann Machines can do very interesting things, and they don’t require labels on the data to learn about the data, making them useful in settings where people have collected a lot of data but don’t have the resources to label all of the data. They can learn structure about the data, which can then be used to classify similar datapoints or even generate new or similar data. They can learn, for instance, what a certain alphabet system’s characters “look like” and generate plausible examples that would fit into the alphabet, or complete part of a character given the other half, which can be useful in filling in missing parts of data. </a></p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Proposal</h3>

<p>The link to the proposal can be found here: <a href="https://github.com/taichia/15418ProjectWebsite/blob/gh-pages/Deep%20Boltzmann%20Machines.pdf">Proposal </a></p>

<h3>
<a id="creating-pages-manually" class="anchor" href="#creating-pages-manually" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Checkpoints:</h3>

<p><ul>
  <li>Week of 11/7: Do research and create the sequential version (Currently in Progress)</li>
  <li>Week of 11/14: Create working parallel version of program</li>
  <li>Week of 11/21: Do tuning on the parallel section to make it as fast as possible</li>
  <li>Week of 11/28: Put together the deliverables (takes a nontrivial amount of time and coding), poster, and website</li>
</ul></p>

<h3>
<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Milestones:</h3>
<p>For our 75% goal, we plan on getting the parallelized version of the machine implemented with CUDA. Currently, we are writing out sequential code with Python, so we had to research how to implement CUDA programming in python. In our research, we found that we can use numbapro to run vectorized python code on the 1080. We also found that benchmarking will be very easy with the built-in profiler (or use nvprof) to see exactly in where in our code and in which device (cpu or gpu) takes the most time. There are a lot of resources available on how to use cuda on python, most of which is found on youtube (CUDAcast #10 and onward).  </p>

<p>For our 100% goal, we would need to tune our CUDA implementation to achieve maximum speed-up. We can do this in several ways, including increasing/decreasing gridsize/blocksize each cuda function, network size, learning rate, etc.</p>

<p>For our 125% goal, we could implement different training algorithms and check their quality/performance against the one we wrote. Such algorithms include the Metropolis-Hastings algorithm, Gibbs sampling, Slice sampling, etc. All of these algorithms can be parallelized in some way, so we can implement crude versions of these algorithms to compare quality/speed. </p>



<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>The two team members that worked on this project are Taichi Akiyama (<a href ="https://github.com/taichia" class="user-mention">@taichia</a>) and Edgar Chen(<a href="https://github.com/EggyLv999" class="user-mention">@EggyLv999</a>). 

      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/taichia">taichia</a> and <a href="https://github.com/EggyLv999">EggyLv999.</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
